{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# === Параметры ===\n",
    "PAD_TOKEN = '<PAD>'\n",
    "EOS_TOKEN = '<EOS>'\n",
    "EMBED_DIM = 64\n",
    "LSTM_UNITS = 64\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "VAL_SPLIT = 0.1\n",
    "\n",
    "# === 1. Загрузка и подготовка данных ===\n",
    "df = pd.read_csv('word_forms.csv', encoding='utf-8')\n",
    "case_names = ['Атооч', 'Илик', 'Барыш', 'Табыш', 'Жатыш', 'Чыгыш']\n",
    "lemmas = df['lemma'].astype(str).tolist()\n",
    "forms_by_case = {case: df[case].astype(str).tolist() for case in case_names}\n",
    "\n",
    "# Собираем алфавит\n",
    "all_words = lemmas + sum([forms_by_case[case] for case in case_names], [])\n",
    "char_set = sorted({ch for word in all_words for ch in word})\n",
    "char_list = [PAD_TOKEN, EOS_TOKEN] + char_set\n",
    "char2idx = {ch: i for i, ch in enumerate(char_list)}\n",
    "idx2char = {i: ch for ch, i in char2idx.items()}\n",
    "vocab_size = len(char2idx)\n",
    "\n",
    "# Сохраняем словарь для инференса\n",
    "with open('char2idx.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(char2idx, f, ensure_ascii=False)\n",
    "\n",
    "# Кодирование слов\n",
    "def encode(word, add_eos=False, max_len=None):\n",
    "    seq = [char2idx.get(ch, 0) for ch in word]\n",
    "    if add_eos:\n",
    "        seq.append(char2idx[EOS_TOKEN])\n",
    "    if max_len:\n",
    "        seq += [char2idx[PAD_TOKEN]] * (max_len - len(seq))\n",
    "    return seq\n",
    "\n",
    "# Вычисление максимальных длин\n",
    "max_len_input = max(len(w) for w in lemmas)\n",
    "max_len_output = max(len(w) for case in case_names for w in forms_by_case[case]) + 1  # +1 за <EOS>\n",
    "\n",
    "# Кодирование всех данных\n",
    "X = np.array([encode(w, add_eos=False, max_len=max_len_input) for w in lemmas], dtype=np.int32)\n",
    "Y = {case: np.array([encode(w, add_eos=True, max_len=max_len_output) for w in forms_by_case[case]], dtype=np.int32) for case in case_names}\n",
    "\n",
    "# Разделение train/val\n",
    "X_train, X_val, idx_train, idx_val = train_test_split(X, np.arange(len(X)), test_size=VAL_SPLIT, random_state=42)\n",
    "Y_train = {case: Y[case][idx_train] for case in case_names}\n",
    "Y_val   = {case: Y[case][idx_val] for case in case_names}\n",
    "\n",
    "# === 2. Архитектура модели ===\n",
    "inputs = layers.Input(shape=(max_len_input,), name='lemma_input')\n",
    "x = layers.Embedding(input_dim=vocab_size, output_dim=EMBED_DIM, mask_zero=True)(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(LSTM_UNITS))(x)  # <--- теперь это работает!\n",
    "outputs = []\n",
    "\n",
    "for case in case_names:\n",
    "    r = layers.RepeatVector(max_len_output)(x)\n",
    "    o = layers.TimeDistributed(layers.Dense(vocab_size, activation='softmax'), name=f\"{case}_output\")(r)\n",
    "    outputs.append(o)\n",
    "\n",
    "model = models.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# === 3. Обучение ===\n",
    "Y_train_list = [Y_train[case] for case in case_names]\n",
    "Y_val_list = [Y_val[case] for case in case_names]\n",
    "\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]\n",
    "\n",
    "model.fit(X_train, Y_train_list,\n",
    "          validation_data=(X_val, Y_val_list),\n",
    "          epochs=EPOCHS,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          callbacks=callbacks)\n",
    "\n",
    "# === 4. Сохранение модели ===\n",
    "model.save('kyrgyz_declension_model')\n",
    "print(\"✅ Модель и словарь успешно сохранены.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
